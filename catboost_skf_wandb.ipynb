{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "import optuna\n",
    "import regex\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WanDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavinkeem\u001b[0m (\u001b[33mremember-us\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/book/davin/level2-bookratingprediction-recsys-03/wandb/run-20241106_072706-6wfn2xi9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/remember-us/active/runs/6wfn2xi9' target=\"_blank\">new_base</a></strong> to <a href='https://wandb.ai/remember-us/active' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/remember-us/active' target=\"_blank\">https://wandb.ai/remember-us/active</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/remember-us/active/runs/6wfn2xi9' target=\"_blank\">https://wandb.ai/remember-us/active/runs/6wfn2xi9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/remember-us/active/runs/6wfn2xi9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa37627d630>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = str(input('run 이름을 입력하세요 :'))\n",
    "# selected_model = str(input('model 명을 입력하세요 (xgb/rf) :'))\n",
    "opt = bool(input('Optuna 사용 여부를 입력하세요 (뭐라도 입력 시 사용) :'))\n",
    "\n",
    "wandb.init(\n",
    "    settings=wandb.Settings(start_method='thread'),\n",
    "    dir=None,  # 로컬에 로그 저장하지 않음\n",
    "    entity='remember-us', # team name,\n",
    "    project='active', # project name\n",
    "    name=run, # run name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path: str = '/data/ephemeral/home/book/data/'\n",
    "users = pd.read_csv(data_path + 'users.csv')\n",
    "books = pd.read_csv(data_path + 'books.csv')\n",
    "train = pd.read_csv(data_path + 'train_ratings.csv')\n",
    "test = pd.read_csv(data_path + 'test_ratings.csv')\n",
    "sub = pd.read_csv(data_path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2list(x: str) -> list:\n",
    "    '''문자열을 리스트로 변환하는 함수'''\n",
    "    return x[2:-2].split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_location(x: str) -> list:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : str\n",
    "        location 데이터\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res : list\n",
    "        location 데이터를 나눈 뒤, 정제한 결과를 반환합니다.\n",
    "        순서는 country, state, city, ... 입니다.\n",
    "    '''\n",
    "    res = x.split(',')\n",
    "    res = [i.strip().lower() for i in res]\n",
    "    res = [regex.sub(r'[^a-zA-Z/ ]', '', i) for i in res]  # remove special characters\n",
    "    res = [i if i not in ['n/a', ''] else np.nan for i in res]  # change 'n/a' into NaN\n",
    "    res.reverse()  # reverse the list to get country, state, city, ... order\n",
    "\n",
    "    for i in range(len(res)-1, 0, -1):\n",
    "        if (res[i] in res[:i]) and (not pd.isna(res[i])):  # remove duplicated values if not NaN\n",
    "            res.pop(i)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(summary_text: str) -> str:\n",
    "    '''\n",
    "    주어진 텍스트 요약을 전처리합니다.\n",
    "\n",
    "    1. 특수 문자 제거\n",
    "    2. 알파벳과 숫자, 공백을 제외한 모든 문자 제거\n",
    "    3. 여러 개의 공백을 하나의 공백으로\n",
    "    4. 문자열의 앞뒤 공백 제거\n",
    "    5. 모든 문자를 소문자로 변환\n",
    "\n",
    "    Args:\n",
    "        summary_text (str): 전처리할 텍스트 문자열\n",
    "\n",
    "    Returns:\n",
    "        str: 전처리된 텍스트 문자열. 입력이 NaN인 경우 'unknown' 반환.\n",
    "    '''\n",
    "    if pd.isna(summary_text):\n",
    "        return 'unknown'  # NaN일 경우 'unknown' 반환\n",
    "    \n",
    "    summary_text = regex.sub('[.,\\'\\'''\\'!?]', '', summary_text)  # 특수 문자 제거\n",
    "    summary_text = regex.sub('[^0-9a-zA-Z\\s]', '', summary_text)  # 알파벳과 숫자, 공백 제외한 문자 제거\n",
    "    summary_text = regex.sub('\\s+', ' ', summary_text)  # 여러 개의 공백을 하나의 공백으로\n",
    "    summary_text = summary_text.lower()  # 소문자로 변환\n",
    "    summary_text = summary_text.strip()  # 앞뒤 공백 제거\n",
    "    return summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_publication(x: int, a: int) -> int:\n",
    "    '''\n",
    "    주어진 연도를 특정 기준에 따라 카테고리화하는 함수입니다.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : int\n",
    "        책의 발행 연도.\n",
    "    a : int\n",
    "        연도를 그룹화할 때 사용할 기준값 (예: 5년 단위로 그룹화).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        카테고리화된 연도를 반환합니다. \n",
    "        - 1970년 이하의 연도는 1970으로 반환합니다.\n",
    "        - 2000년 초과의 연도는 2006으로 반환합니다.\n",
    "        - 나머지 연도는 a 값에 맞게 그룹화하여 반환합니다.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    books['years'] = books['year_of_publication'].apply(lambda x: categorize_publication(x, 5))\n",
    "    print(books['years'].value_counts())\n",
    "    '''\n",
    "    if x <= 1970:\n",
    "        return 1970\n",
    "    elif x > 2000:\n",
    "        return 2006\n",
    "    else:\n",
    "        return x // a * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_language_from_isbn(isbn):\n",
    "    '''\n",
    "    ISBN 정보를 사용하여 언어 코드를 추출하는 함수입니다.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    isbn : str\n",
    "        책의 ISBN 번호.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        ISBN에서 추출한 언어 코드. ISBN이 비어있거나 형식에 맞지 않을 경우 최빈값 'en'을 반환합니다.\n",
    "        - isbn_language_map 참고\n",
    "        - 기타 언어 코드: isbn_language_map에 정의된 국가 코드를 기반으로 반환\n",
    "    '''\n",
    "    isbn_language_map = {\n",
    "        '0': 'en', '1': 'en', '2': 'fr', '3': 'de', '4': 'ja',\n",
    "        '5': 'ru', '7': 'zh-CN', '82': 'no', '84': 'es', '87': 'da',\n",
    "        '88': 'it', '89': 'ko', '94': 'nl', '600': 'fa', '602': 'ms',\n",
    "        '606': 'ro', '604': 'vi', '618': 'el', '967': 'ms', '974': 'th',\n",
    "        '989': 'pt'\n",
    "    }\n",
    "    if not isbn or not isbn.isdigit():\n",
    "        return 'en'  # 기본값 영어권\n",
    "    for prefix, language in isbn_language_map.items():\n",
    "        if isbn.startswith(prefix):\n",
    "            return language\n",
    "    return 'en'  # 기본값 영어권"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_language_using_isbn(books):\n",
    "    '''\n",
    "    ISBN 정보를 활용하여 language 결측치를 대체하는 함수입니다.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    books : pd.DataFrame\n",
    "        책 정보가 담긴 DataFrame. 반드시 'isbn' 및 'language' 열을 포함해야 합니다.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        language 결측치가 ISBN 정보를 사용해 대체된 DataFrame. ISBN에서 언어를 추출할 수 없는 경우\n",
    "        기본값 'en'으로 대체됩니다.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    books = replace_language_using_isbn(books)\n",
    "    '''\n",
    "    books['extracted_language'] = books['isbn'].apply(extract_language_from_isbn)\n",
    "    books['language'] = books.apply(\n",
    "        lambda row: row['extracted_language'] if pd.isna(row['language']) else row['language'],\n",
    "        axis=1\n",
    "    )\n",
    "    books.drop(columns=['extracted_language'], inplace=True)\n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_age(x: int, a: int) -> int:\n",
    "    '''\n",
    "    주어진 나이를 특정 기준에 따라 카테고리화하는 함수입니다.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : int\n",
    "        유저의 나이.\n",
    "    a : int\n",
    "        나이를 그룹화할 때 사용할 기준값 (예: 10년 단위로 그룹화).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        카테고리화된 나이를 반환합니다. \n",
    "        - 20년 미만의 나이는 10으로 반환합니다.\n",
    "        - 60년 이상의 나이는 60으로 반환합니다.\n",
    "        - 나머지 나이는 a 값에 맞게 그룹화하여 반환합니다.\n",
    "    '''\n",
    "    if x < 20:\n",
    "        return 10\n",
    "    elif x >= 60:\n",
    "        return 60\n",
    "    else:\n",
    "        return x // a * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ = users.copy()\n",
    "books_ = books.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books 데이터 전처리\n",
    "books_['book_title'] = books_['book_title'].apply(text_preprocessing)\n",
    "books_['book_author'] = books_['book_author'].apply(text_preprocessing)\n",
    "books_['publisher'] = books_['publisher'].apply(text_preprocessing)\n",
    "books_['publication_range'] = books_['year_of_publication'].apply(lambda x: categorize_publication(x, 5))\n",
    "books_ = replace_language_using_isbn(books_)\n",
    "books_['category'] = books_['category'].apply(lambda x: str2list(x)[0] if not pd.isna(x) else np.nan)\n",
    "books_['category'] = books_['category'].apply(text_preprocessing)\n",
    "high_categories = ['fiction', 'biography', 'history', 'religion', 'nonfiction', 'social', 'science', 'humor', 'body', \n",
    "                'business', 'economics', 'cook', 'health', 'fitness', 'famil', 'relationship', \n",
    "                'computer', 'travel', 'selfhelp', 'psychology', 'poetry', 'art', 'critic', 'nature', 'philosophy', \n",
    "                'reference','drama', 'sports', 'politic', 'comic', 'novel', 'craft', 'language', 'education', 'crime', 'music', 'pet', \n",
    "                'child', 'collection', 'mystery', 'garden', 'medical', 'author', 'house','technology', 'engineering', 'animal', 'photography',\n",
    "                'adventure', 'game', 'science fiction', 'architecture', 'law', 'fantasy', 'antique', 'friend', 'brother', 'sister', 'cat',\n",
    "                'math', 'christ', 'bible', 'fairy', 'horror', 'design', 'adolescence', 'actor', 'dog', 'transportation', 'murder', 'adultery', 'short', 'bear'\n",
    "                ]\n",
    "# high_category 열을 초기화\n",
    "books_['high_category'] = None\n",
    "# 각 카테고리에 대해 반복하며 매핑\n",
    "for high_category in high_categories:\n",
    "    # category 열에서 high_category가 포함된 행을 찾고, 해당 행의 high_category 열을 업데이트\n",
    "    books_.loc[books_['category'].str.contains(high_category, case=False, na=False), 'high_category'] = high_category\n",
    "books_['high_category'] = books_['high_category'].fillna('others') # 결측치를 'others'로 대체\n",
    "\n",
    "# users 데이터 전처리\n",
    "users_['age'] = users_['age'].fillna(users_['age'].mean())\n",
    "users_['age_range'] = users_['age'].apply(lambda x: categorize_age(x, 10))\n",
    "\n",
    "users_['location_list'] = users_['location'].apply(lambda x: split_location(x)) \n",
    "users_['location_country'] = users_['location_list'].apply(lambda x: x[0])\n",
    "users_['location_state'] = users_['location_list'].apply(lambda x: x[1] if len(x) > 1 else np.nan)\n",
    "users_['location_city'] = users_['location_list'].apply(lambda x: x[2] if len(x) > 2 else np.nan)\n",
    "for idx, row in users_.iterrows():\n",
    "    if (not pd.isna(row['location_state'])) and pd.isna(row['location_country']):\n",
    "        fill_country = users_[users_['location_state'] == row['location_state']]['location_country'].mode()\n",
    "        fill_country = fill_country[0] if len(fill_country) > 0 else np.nan\n",
    "        users_.loc[idx, 'location_country'] = fill_country\n",
    "    elif (not pd.isna(row['location_city'])) and pd.isna(row['location_state']):\n",
    "        if not pd.isna(row['location_country']):\n",
    "            fill_state = users_[(users_['location_country'] == row['location_country']) \n",
    "                                & (users_['location_city'] == row['location_city'])]['location_state'].mode()\n",
    "            fill_state = fill_state[0] if len(fill_state) > 0 else np.nan\n",
    "            users_.loc[idx, 'location_state'] = fill_state\n",
    "        else:\n",
    "            fill_state = users_[users_['location_city'] == row['location_city']]['location_state'].mode()\n",
    "            fill_state = fill_state[0] if len(fill_state) > 0 else np.nan\n",
    "            fill_country = users_[users_['location_city'] == row['location_city']]['location_country'].mode()\n",
    "            fill_country = fill_country[0] if len(fill_country) > 0 else np.nan\n",
    "            users_.loc[idx, 'location_country'] = fill_country\n",
    "            users_.loc[idx, 'location_state'] = fill_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_country 열의 최빈값을 계산\n",
    "most_frequent_country = users_['location_country'].mode()[0]\n",
    "# NaN 값을 최빈값으로 대체\n",
    "users_['location_country'] = users_['location_country'].fillna(most_frequent_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68092 entries, 0 to 68091\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   user_id           68092 non-null  int64  \n",
      " 1   location          68092 non-null  object \n",
      " 2   age               68092 non-null  float64\n",
      " 3   age_range         68092 non-null  float64\n",
      " 4   location_list     68092 non-null  object \n",
      " 5   location_country  68092 non-null  object \n",
      " 6   location_state    67368 non-null  object \n",
      " 7   location_city     65305 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "users_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149570 entries, 0 to 149569\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   isbn                 149570 non-null  object \n",
      " 1   book_title           149570 non-null  object \n",
      " 2   book_author          149570 non-null  object \n",
      " 3   year_of_publication  149570 non-null  float64\n",
      " 4   publisher            149570 non-null  object \n",
      " 5   img_url              149570 non-null  object \n",
      " 6   language             149570 non-null  object \n",
      " 7   category             149570 non-null  object \n",
      " 8   summary              82343 non-null   object \n",
      " 9   img_path             149570 non-null  object \n",
      " 10  publication_range    149570 non-null  float64\n",
      " 11  high_category        149570 non-null  object \n",
      "dtypes: float64(2), object(10)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "books_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_final = users_[['user_id', 'age_range', 'location_country']]\n",
    "books_final = books_[['isbn', 'book_title', 'book_author', 'publisher', 'language', 'high_category', 'publication_range']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 병합\n",
    "train = train.merge(users_final, on='user_id').merge(books_final, on='isbn')\n",
    "test = test.merge(users_final, on='user_id').merge(books_final, on='isbn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'isbn', 'rating', 'age_range', 'location_country',\n",
       "       'book_title', 'book_author', 'publisher', 'language', 'high_category',\n",
       "       'publication_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306795 entries, 0 to 306794\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   user_id            306795 non-null  int64  \n",
      " 1   isbn               306795 non-null  object \n",
      " 2   rating             306795 non-null  int64  \n",
      " 3   age_range          306795 non-null  float64\n",
      " 4   location_country   306795 non-null  object \n",
      " 5   book_title         306795 non-null  object \n",
      " 6   book_author        306795 non-null  object \n",
      " 7   publisher          306795 non-null  object \n",
      " 8   language           306795 non-null  object \n",
      " 9   high_category      306795 non-null  object \n",
      " 10  publication_range  306795 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 25.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76699 entries, 0 to 76698\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   user_id            76699 non-null  int64  \n",
      " 1   isbn               76699 non-null  object \n",
      " 2   rating             76699 non-null  int64  \n",
      " 3   age_range          76699 non-null  float64\n",
      " 4   location_country   76699 non-null  object \n",
      " 5   book_title         76699 non-null  object \n",
      " 6   book_author        76699 non-null  object \n",
      " 7   publisher          76699 non-null  object \n",
      " 8   language           76699 non-null  object \n",
      " 9   high_category      76699 non-null  object \n",
      " 10  publication_range  76699 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_counts = train['user_id'].value_counts()\n",
    "train['user_review_counts'] = train['user_id'].map(user_id_counts)\n",
    "test['user_review_counts'] = test['user_id'].map(user_id_counts)\n",
    "test['user_review_counts'] = test['user_review_counts'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_isbn_counts = train['isbn'].value_counts()\n",
    "train['book_review_counts'] = train['isbn'].map(book_isbn_counts)\n",
    "test['book_review_counts'] = test['isbn'].map(book_isbn_counts)\n",
    "test['book_review_counts'] = test['book_review_counts'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['isbn', 'book_title', 'book_author', 'publisher', 'language', 'high_category', 'publication_range', 'user_id', 'age_range', 'location_country']\n",
    "num_col = ['rating', 'user_review_counts', 'book_review_counts']\n",
    "\n",
    "for df in [train, test] :\n",
    "    for cat in cat_col :\n",
    "        df[cat] = df[cat].astype('str')\n",
    "    for num in num_col :\n",
    "        df[num] = df[num].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_col:\n",
    "    combined_values = pd.concat([train[col], test[col]]).unique()\n",
    "    train[col] = pd.Categorical(train[col], categories=combined_values).codes\n",
    "    test[col] = pd.Categorical(test[col], categories=combined_values).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRIC 함수\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    metrics = {\n",
    "        'RMSE' : root_mean_squared_error(y_true, y_pred),\n",
    "        'MSE' : mean_squared_error(y_true, y_pred),\n",
    "        'MAE' : mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skf_train(X_data, y_data, params):\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "    valid_rmse = []\n",
    "    valid_mse = []\n",
    "    valid_mae = []\n",
    "    pred_df = pd.DataFrame()\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in tqdm.tqdm(enumerate(skf.split(X_data, y_data)), total = skf.n_splits) : \n",
    "        \n",
    "        # Train Set과 Valid Set 분할    \n",
    "        X_train, y_train = X_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        X_valid, y_valid = X_data.iloc[valid_idx], y_data.iloc[valid_idx]\n",
    "        \n",
    "        train_data = Pool(data = X_train, label = y_train, cat_features = cat_col)\n",
    "        valid_data = Pool(data = X_valid, label = y_valid, cat_features = cat_col)\n",
    "        \n",
    "        cat_model = CatBoostRegressor(**params, iterations = 1000, \n",
    "                                    loss_function = 'RMSE', eval_metric = 'RMSE', \n",
    "                                    use_best_model = True, random_state = 42,\n",
    "                                    cat_features = [i for i in range(0, 10)])\n",
    "        cat_model.fit(train_data, eval_set = [train_data, valid_data], use_best_model = True, verbose = 100, early_stopping_rounds = 100)\n",
    "        \n",
    "        # 모델 RMSE\n",
    "        valid_metrics = calculate_metrics(y_valid, cat_model.predict(X_valid))\n",
    "        print(f'Fold {fold + 1} Valid RMSE: {valid_metrics['RMSE']}')\n",
    "        print(f'Fold {fold + 1} Valid MSE:  {valid_metrics['MSE']}')\n",
    "        print(f'Fold {fold + 1} Valid MAE:  {valid_metrics['MAE']}')\n",
    "        valid_rmse.append(valid_metrics['RMSE'])\n",
    "        valid_mse.append(valid_metrics['MSE'])\n",
    "        valid_mae.append(valid_metrics['MAE'])\n",
    "\n",
    "        wandb.log({\n",
    "            'Valid RMSE': valid_metrics['RMSE'],\n",
    "            'Valid MSE': valid_metrics['MSE'],\n",
    "            'Valid MAE': valid_metrics['MAE']\n",
    "        })\n",
    "        \n",
    "        # Predict\n",
    "        pred = cat_model.predict(test.drop(['rating'], axis = 1))\n",
    "        pred_df[f'pred_{fold}'] = pred\n",
    "        \n",
    "    print(f'RMSE 평균 : {np.array(valid_rmse).mean():.4f} \\n')\n",
    "\n",
    "    params = json.dumps(params)\n",
    "    wandb.log({\n",
    "        'Valid RMSE': np.array(valid_rmse).mean(),\n",
    "        'Valid MSE': np.array(valid_mse).mean(),\n",
    "        'Valid MAE': np.array(valid_mae).mean(),\n",
    "        'param': params,\n",
    "        'features': list(X_data.columns)\n",
    "    })\n",
    "    wandb.finish()\n",
    "\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_train(X_data, y_data):\n",
    "    def train(X_data, y_data, params):\n",
    "        \n",
    "        # Train Set과 Valid Set 분할    \n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_data, y_data, test_size=0.2, random_state=42, stratify=y_data)\n",
    "        \n",
    "        train_data = Pool(data = X_train, label = y_train, cat_features = cat_col)\n",
    "        valid_data = Pool(data = X_valid, label = y_valid, cat_features = cat_col)\n",
    "        \n",
    "        cat_model = CatBoostRegressor(**params, iterations = 500, \n",
    "                                    loss_function = 'RMSE', eval_metric = 'RMSE', \n",
    "                                    use_best_model = True, random_state = 42,\n",
    "                                    cat_features = [i for i in range(0, 10)])\n",
    "        cat_model.fit(train_data, eval_set = [train_data, valid_data], use_best_model = True,\n",
    "                    verbose = 500, early_stopping_rounds = 100)\n",
    "        \n",
    "        valid_metrics = calculate_metrics(y_valid, cat_model.predict(X_valid))\n",
    "\n",
    "        return valid_metrics['RMSE']\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "            'depth': trial.suggest_int('depth', 3, 10),\n",
    "            'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n",
    "            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 1.0),\n",
    "            'boosting_type': 'Plain',\n",
    "            'bootstrap_type': 'MVS',\n",
    "            'devices': 'cuda',\n",
    "        }\n",
    "        return train(X_data, y_data, params=params)\n",
    "        \n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3089768\ttest: 2.2250116\ttest1: 2.2853245\tbest: 2.2853245 (0)\ttotal: 366ms\tremaining: 30m 27s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 2.131574843\n",
      "bestIteration = 121\n",
      "\n",
      "Shrink model to first 122 iterations.\n",
      "Fold 1 Valid RMSE: 2.131574842982223\n",
      "Fold 1 Valid MSE:  4.54361131123469\n",
      "Fold 1 Valid MAE:  1.6060710603646966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:00<09:03, 60.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3086276\ttest: 2.2304251\ttest1: 2.2819052\tbest: 2.2819052 (0)\ttotal: 262ms\tremaining: 21m 50s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 2.121281341\n",
      "bestIteration = 125\n",
      "\n",
      "Shrink model to first 126 iterations.\n",
      "Fold 2 Valid RMSE: 2.1212813406764597\n",
      "Fold 2 Valid MSE:  4.499834526302117\n",
      "Fold 2 Valid MAE:  1.5987580005170183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:02<08:10, 61.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3073767\ttest: 2.2298368\ttest1: 2.2827817\tbest: 2.2827817 (0)\ttotal: 260ms\tremaining: 21m 40s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 2.125795517\n",
      "bestIteration = 128\n",
      "\n",
      "Shrink model to first 129 iterations.\n",
      "Fold 3 Valid RMSE: 2.125795516673779\n",
      "Fold 3 Valid MSE:  4.519006578710339\n",
      "Fold 3 Valid MAE:  1.5946089763228533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:03<07:09, 61.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3063828\ttest: 2.2281942\ttest1: 2.2798017\tbest: 2.2798017 (0)\ttotal: 304ms\tremaining: 25m 19s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 2.128504648\n",
      "bestIteration = 174\n",
      "\n",
      "Shrink model to first 175 iterations.\n",
      "Fold 4 Valid RMSE: 2.128504647617931\n",
      "Fold 4 Valid MSE:  4.530532034931133\n",
      "Fold 4 Valid MAE:  1.60240777524099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [04:18<06:39, 66.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3059614\ttest: 2.2229838\ttest1: 2.2868860\tbest: 2.2868860 (0)\ttotal: 278ms\tremaining: 23m 11s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 2.132718509\n",
      "bestIteration = 207\n",
      "\n",
      "Shrink model to first 208 iterations.\n",
      "Fold 5 Valid RMSE: 2.1327185087166454\n",
      "Fold 5 Valid MSE:  4.548488237422551\n",
      "Fold 5 Valid MAE:  1.6045215700432736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [05:42<06:05, 73.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3044032\ttest: 2.1735279\ttest1: 2.2805231\tbest: 2.2805231 (0)\ttotal: 242ms\tremaining: 20m 11s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 2.133198656\n",
      "bestIteration = 149\n",
      "\n",
      "Shrink model to first 150 iterations.\n",
      "Fold 6 Valid RMSE: 2.1331986562049314\n",
      "Fold 6 Valid MSE:  4.550536506834526\n",
      "Fold 6 Valid MAE:  1.5978899422429946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [06:51<04:46, 71.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3027754\ttest: 2.1715789\ttest1: 2.2765302\tbest: 2.2765302 (0)\ttotal: 228ms\tremaining: 18m 57s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 2.130374694\n",
      "bestIteration = 135\n",
      "\n",
      "Shrink model to first 136 iterations.\n",
      "Fold 7 Valid RMSE: 2.130374693805442\n",
      "Fold 7 Valid MSE:  4.538496336006632\n",
      "Fold 7 Valid MAE:  1.5980427661209966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [07:53<03:25, 68.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3014046\ttest: 2.1886918\ttest1: 2.2768861\tbest: 2.2768861 (0)\ttotal: 235ms\tremaining: 19m 34s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 2.138187885\n",
      "bestIteration = 111\n",
      "\n",
      "Shrink model to first 112 iterations.\n",
      "Fold 8 Valid RMSE: 2.138187885378161\n",
      "Fold 8 Valid MSE:  4.571847433177932\n",
      "Fold 8 Valid MAE:  1.6049198734772265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [08:52<02:10, 65.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3017454\ttest: 2.1712629\ttest1: 2.2774790\tbest: 2.2774790 (0)\ttotal: 242ms\tremaining: 20m 9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 2.131864068\n",
      "bestIteration = 111\n",
      "\n",
      "Shrink model to first 112 iterations.\n",
      "Fold 9 Valid RMSE: 2.131864067669618\n",
      "Fold 9 Valid MSE:  4.544844403020851\n",
      "Fold 9 Valid MAE:  1.6018479078848558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [09:50<01:03, 63.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3037831\ttest: 2.1710382\ttest1: 2.2778358\tbest: 2.2778358 (0)\ttotal: 273ms\tremaining: 22m 45s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 2.132075392\n",
      "bestIteration = 149\n",
      "\n",
      "Shrink model to first 150 iterations.\n",
      "Fold 10 Valid RMSE: 2.132075391907796\n",
      "Fold 10 Valid MSE:  4.545745476778782\n",
      "Fold 10 Valid MAE:  1.6025330645749847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:58<00:00, 65.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 평균 : 2.1306 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c7800f7b984a1eb5f36ceb050761ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Valid MAE</td><td>█▄▁▆▇▃▃▇▅▆</td></tr><tr><td>Valid MSE</td><td>▅▁▃▄▆▆▅█▅▅</td></tr><tr><td>Valid RMSE</td><td>▅▁▃▄▆▆▅█▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Valid MAE</td><td>1.60253</td></tr><tr><td>Valid MSE</td><td>4.54575</td></tr><tr><td>Valid RMSE</td><td>2.13208</td></tr><tr><td>param</td><td>{\"learning_rate\": 0....</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">new_base</strong> at: <a href='https://wandb.ai/remember-us/active/runs/6wfn2xi9' target=\"_blank\">https://wandb.ai/remember-us/active/runs/6wfn2xi9</a><br/> View project at: <a href='https://wandb.ai/remember-us/active' target=\"_blank\">https://wandb.ai/remember-us/active</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241106_072706-6wfn2xi9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_data, y_data = train.drop(columns = 'rating'), train['rating']\n",
    "\n",
    "if opt:\n",
    "    best_params = optuna_train(X_data, y_data)\n",
    "else:\n",
    "    best_params = {\n",
    "        'learning_rate': 0.5,\n",
    "        'depth': 7,\n",
    "        'colsample_bylevel': 0.5,\n",
    "        'boosting_type': 'Plain',\n",
    "        'bootstrap_type': 'MVS',\n",
    "        'devices': 'cuda',\n",
    "    }\n",
    "pred_df = skf_train(X_data, y_data, params=best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11676</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116866</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152827</td>\n",
       "      <td>0060973129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157969</td>\n",
       "      <td>0374157065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67958</td>\n",
       "      <td>0399135782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76694</th>\n",
       "      <td>278543</td>\n",
       "      <td>1576734218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76695</th>\n",
       "      <td>278563</td>\n",
       "      <td>3492223710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76696</th>\n",
       "      <td>278633</td>\n",
       "      <td>1896095186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76697</th>\n",
       "      <td>278668</td>\n",
       "      <td>8408044079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76698</th>\n",
       "      <td>278851</td>\n",
       "      <td>0767907566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76699 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id        isbn  rating\n",
       "0        11676  0002005018       0\n",
       "1       116866  0002005018       0\n",
       "2       152827  0060973129       0\n",
       "3       157969  0374157065       0\n",
       "4        67958  0399135782       0\n",
       "...        ...         ...     ...\n",
       "76694   278543  1576734218       0\n",
       "76695   278563  3492223710       0\n",
       "76696   278633  1896095186       0\n",
       "76697   278668  8408044079       0\n",
       "76698   278851  0767907566       0\n",
       "\n",
       "[76699 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11676</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>6.611996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116866</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>7.031770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152827</td>\n",
       "      <td>0060973129</td>\n",
       "      <td>7.409333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157969</td>\n",
       "      <td>0374157065</td>\n",
       "      <td>7.469658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67958</td>\n",
       "      <td>0399135782</td>\n",
       "      <td>7.640977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76694</th>\n",
       "      <td>278543</td>\n",
       "      <td>1576734218</td>\n",
       "      <td>6.303957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76695</th>\n",
       "      <td>278563</td>\n",
       "      <td>3492223710</td>\n",
       "      <td>5.997220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76696</th>\n",
       "      <td>278633</td>\n",
       "      <td>1896095186</td>\n",
       "      <td>6.233525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76697</th>\n",
       "      <td>278668</td>\n",
       "      <td>8408044079</td>\n",
       "      <td>5.225945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76698</th>\n",
       "      <td>278851</td>\n",
       "      <td>0767907566</td>\n",
       "      <td>5.614932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76699 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id        isbn    rating\n",
       "0        11676  0002005018  6.611996\n",
       "1       116866  0002005018  7.031770\n",
       "2       152827  0060973129  7.409333\n",
       "3       157969  0374157065  7.469658\n",
       "4        67958  0399135782  7.640977\n",
       "...        ...         ...       ...\n",
       "76694   278543  1576734218  6.303957\n",
       "76695   278563  3492223710  5.997220\n",
       "76696   278633  1896095186  6.233525\n",
       "76697   278668  8408044079  5.225945\n",
       "76698   278851  0767907566  5.614932\n",
       "\n",
       "[76699 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['rating'] = (pred_df['pred_0'] + pred_df['pred_1'] + pred_df['pred_2'] + pred_df['pred_3'] + pred_df['pred_4'] + \n",
    "                               pred_df['pred_5'] + pred_df['pred_6'] + pred_df['pred_7'] + pred_df['pred_8'] + pred_df['pred_9']) / 10\n",
    "submit = sub[['user_id', 'isbn', 'rating']]\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submit.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
